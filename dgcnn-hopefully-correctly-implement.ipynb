{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13011574,"sourceType":"datasetVersion","datasetId":8237691}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport h5py\nimport json\nimport torch\nimport logging\nfrom torch.utils.data import Dataset\nimport numpy as np\n# from .build import DATASETS\n# from utils.logger import print\n\ndef rotate_point_cloud_z(pc):\n    \"\"\" Randomly rotate the point clouds to augment the dataset \"\"\"\n    rotation_angle = np.random.uniform() * 2 * np.pi\n    cosval = np.cos(rotation_angle)\n    sinval = np.sin(rotation_angle)\n    rotation_matrix = np.array([[cosval, -sinval, 0],\n                                [sinval, cosval, 0],\n                                [0, 0, 1]])\n    rotated_data = np.dot(pc, rotation_matrix)\n    return rotated_data\n\ndef jitter_point_cloud(pc, sigma=0.01, clip=0.05):\n    \"\"\" Randomly jitter points. jittering is per point. \"\"\"\n    N, C = pc.shape\n    assert(clip > 0)\n    jittered_data = np.clip(sigma * np.random.randn(N, C), -1 * clip, clip)\n    jittered_data += pc\n    return jittered_data\n\ndef random_scale_point_cloud(pc, scale_low=0.8, scale_high=1.25):\n    \"\"\" Randomly scale the point cloud. Scale is per shape. \"\"\"\n    scale = np.random.uniform(scale_low, scale_high)\n    return pc * scale\n\n\n# @DATASETS.register_module()\nclass ShapeNetPartH5(Dataset):\n    \"\"\"\n    Dataloader for the HDF5 version of ShapeNetPart.\n    This is the standard dataset format used in PointNet/PointNet++ and subsequent works.\n    \"\"\"\n    # 50-class mapping for ShapeNetPart\n    seg_classes = {\n        'Airplane': [0, 1, 2, 3], 'Bag': [4, 5], 'Cap': [6, 7], 'Car': [8, 9, 10, 11],\n        'Chair': [12, 13, 14, 15], 'Earphone': [16, 17, 18], 'Guitar': [19, 20, 21],\n        'Knife': [22, 23], 'Lamp': [24, 25, 26, 27], 'Laptop': [28, 29],\n        'Motorbike': [30, 31, 32, 33, 34, 35], 'Mug': [36, 37], 'Pistol': [38, 39, 40],\n        'Rocket': [41, 42, 43], 'Skateboard': [44, 45, 46], 'Table': [47, 48, 49]\n    }\n    \n    # Mapping from category name to the class index (0-15)\n    classes_map = {\n        'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5,\n        'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10,\n        'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15\n    }\n\n    def __init__(self, config):\n        self.root = config.DATA_PATH\n        self.npoints = config.N_POINTS\n        self.split = config.subset\n        self.use_augmentation = (self.split == 'train')\n\n        self.all_points = []\n        self.all_seg_labels = []\n        self.all_cls_labels = []\n\n        # Find all H5 files for the given split (train/test/val)\n        h5_files = [f for f in os.listdir(self.root) if f.endswith('.h5') and self.split in f]\n        if not h5_files:\n            raise FileNotFoundError(f\"No H5 files found for split '{self.split}' in '{self.root}'\")\n        \n        print(f\"Loading H5 files for '{self.split}' split: {h5_files}\")\n\n        for h5_filename in sorted(h5_files):\n            f = h5py.File(os.path.join(self.root, h5_filename), 'r')\n            points = f['data'][:]\n            seg_labels = f['seg'][:] \n            cls_labels = f['label'][:]\n            f.close()\n            \n            self.all_points.append(points)\n            self.all_seg_labels.append(seg_labels)\n            self.all_cls_labels.append(cls_labels)\n\n        # Concatenate data from all loaded files\n        self.all_points = np.concatenate(self.all_points, axis=0)\n        self.all_seg_labels = np.concatenate(self.all_seg_labels, axis=0)\n        self.all_cls_labels = np.concatenate(self.all_cls_labels, axis=0).squeeze() # Squeeze to make it 1D\n\n        print(f'The size of {self.split} data is {len(self.all_points)}')\n        print(f'Number of points per sample: {self.npoints}')\n        \n        self.classes = self.classes_map\n        \n    def __len__(self):\n        return len(self.all_points)\n\n    def __getitem__(self, index):\n        points = self.all_points[index][:self.npoints].copy()\n        seg_labels = self.all_seg_labels[index][:self.npoints].copy()\n        cls_label = self.all_cls_labels[index].copy()\n\n        # Augmentation is applied only to the training set\n        if self.use_augmentation:\n            points = rotate_point_cloud_z(points)\n            points = jitter_point_cloud(points)\n            points = random_scale_point_cloud(points)\n        \n        # Normalize points\n        points = self.pc_normalize(points)\n\n\n        return (\n            torch.from_numpy(points).float(),\n            torch.from_numpy(np.array([cls_label])).long(), # Wrap in array for consistent shape\n            torch.from_numpy(seg_labels).long()\n        )\n\n    @staticmethod\n    def pc_normalize(pc):\n        centroid = np.mean(pc, axis=0)\n        pc = pc - centroid\n        m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n        pc = pc / (m + 1e-9)\n        return pc\n    \n\n\nif __name__ == \"__main__\":\n    import sys\n    import random\n    # project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n    # sys.path.insert(0, project_root)\n\n    class DummyConfig1:\n        def __init__(self):\n            # --- IMPORTANT ---\n            # This path must point to the folder containing the .h5 files\n            self.DATA_PATH = '/kaggle/input/shapenetpart/shapenetpart_hdf5_2048'\n            self.N_POINTS = 2048\n            self.subset = 'train'  # can be 'train' or 'test'\n\n    config = DummyConfig1()\n    \n    print(f\"--- Testing ShapeNetPart HDF5 Dataset ---\")\n    print(f\"Loading data from: {config.DATA_PATH}\")\n    print(f\"Subset: {config.subset}, Points per sample: {config.N_POINTS}\")\n    \n    # 2. --- Instantiate the dataset ---\n    try:\n        dataset_train = ShapeNetPartH5(config)\n        \n    except Exception as e:\n        print(f\"\\n[ERROR] Failed to initialize dataset. Please check the DATA_PATH in the script.\")\n        print(f\"Details: {e}\")\n        exit()\n    # 3. --- Get and inspect a random sample ---\n    if len(dataset_train) == 0:\n        print(\"\\n[ERROR] The dataset is empty. No data was found. Check the DATA_PATH and dataset structure.\")\n    else:\n        print(f\"\\nDataset loaded successfully with {len(dataset_train)} samples.\")\n        \n        # The new dataloader has a map from name to class index. We need the reverse for printing.\n        idx_to_name_map = {v: k for k, v in dataset_train.classes_map.items()}\n        \n        # Get a random item\n        random_index = random.randint(0, len(dataset_train) - 1)\n        print(f\"Fetching random sample at index: {random_index}\")\n        \n        # The __getitem__ method returns a tuple of tensors\n        points_tensor, cls_label_tensor, seg_labels_tensor = dataset_train[random_index]   # first is all points and their coordinates second is object category third is label pr points\n        \n        # --- NEW LOGIC TO GET CATEGORY NAME (continued) ---\n        # Get the category index from the tensor, then look up its name\n        cat_idx = cls_label_tensor.item()\n        cat_name = idx_to_name_map.get(cat_idx, f\"UnknownCategory_{cat_idx}\")\n        \n        print(f\"\\n--- Sample Details for Category: {cat_name} ---\")\n        \n        # Check shapes\n        print(f\"Points tensor shape:      {points_tensor.shape} (Expected: [{config.N_POINTS}, 3])\")\n        print(f\"Class label tensor shape:   {cls_label_tensor.shape} (Expected: [1])\")\n        print(f\"Seg labels tensor shape:  {seg_labels_tensor.shape} (Expected: [{config.N_POINTS}])\")\n        \n        # Check dtypes\n        print(f\"\\nPoints tensor dtype:      {points_tensor.dtype}\")\n        print(f\"Class label tensor dtype:   {cls_label_tensor.dtype}\")\n        print(f\"Seg labels tensor dtype:  {seg_labels_tensor.dtype}\")\n        \n        # Check content\n        class_label = cls_label_tensor.item()\n        print(f\"\\nClass label value: {class_label}\")\n        \n        # This part of the check remains the same and is still the most important one\n        unique_labels, counts = np.unique(seg_labels_tensor.numpy(), return_counts=True)\n        print(\"\\n--- Segmentation Label Analysis ---\")\n        print(\"This is the most crucial check. If you see multiple labels, the loader is working.\")\n        print(f\"Unique part labels found in sample: {unique_labels}\")\n        print(f\"Point counts for each label:      {counts}\")\n\n        if len(unique_labels) <= 1:\n            print(\"\\n[WARNING] Only one unique label was found. The part segmentation data may not be loading correctly.\")\n        else:\n            print(\"\\n[SUCCESS] Multiple unique labels found. The dataset appears to be loading part data correctly.\")\n\n\n        print(type(dataset_train))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:11:33.276263Z","iopub.execute_input":"2025-10-10T09:11:33.276558Z","iopub.status.idle":"2025-10-10T09:11:42.930345Z","shell.execute_reply.started":"2025-10-10T09:11:33.276534Z","shell.execute_reply":"2025-10-10T09:11:42.929289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DummyConfig2:\n        def __init__(self):\n            # --- IMPORTANT ---\n            # This path must point to the folder containing the .h5 files\n            self.DATA_PATH = '/kaggle/input/shapenetpart/shapenetpart_hdf5_2048'\n            self.N_POINTS = 2048\n            self.subset = 'test' \n\n\n\nconfig2 = DummyConfig2()\ndataset_test = ShapeNetPartH5(config2)\nprint(len(dataset_test))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:11:46.449881Z","iopub.execute_input":"2025-10-10T09:11:46.450808Z","iopub.status.idle":"2025-10-10T09:11:47.181123Z","shell.execute_reply.started":"2025-10-10T09:11:46.450773Z","shell.execute_reply":"2025-10-10T09:11:47.180035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"category_to_parts = dataset_train.seg_classes\ncategory_to_parts\ncategory_to_index = dataset_train.classes_map\ncategory_to_index\nindex_to_category = {v:k for k,v in category_to_index.items()}\nindex_to_category","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:11:48.835977Z","iopub.execute_input":"2025-10-10T09:11:48.836403Z","iopub.status.idle":"2025-10-10T09:11:48.848966Z","shell.execute_reply.started":"2025-10-10T09:11:48.836369Z","shell.execute_reply":"2025-10-10T09:11:48.847986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DummyConfig3:\n        def __init__(self):\n            # --- IMPORTANT ---\n            # This path must point to the folder containing the .h5 files\n            self.DATA_PATH = '/kaggle/input/shapenetpart/shapenetpart_hdf5_2048'\n            self.N_POINTS = 2048\n            self.subset = 'val' \n\nconfig3 = DummyConfig3()\ndataset_val = ShapeNetPartH5(config3)\nprint(len(dataset_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:11:51.371927Z","iopub.execute_input":"2025-10-10T09:11:51.372572Z","iopub.status.idle":"2025-10-10T09:11:51.888829Z","shell.execute_reply.started":"2025-10-10T09:11:51.372545Z","shell.execute_reply":"2025-10-10T09:11:51.887951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\nimport pandas as pd\nimport numpy as np\n\ndef visualize_point_cloud_interactive(sample):\n    \"\"\"\n    sample: a tuple from your dataset, e.g., (points, labels) or (points, labels, seg)\n    \"\"\"\n    points,classes,labels = sample\n    # labels = dataset_train[1] if len(sample) > 1 else np.zeros(points.shape[0])\n    \n    # Convert to NumPy if torch tensor\n    # if not isinstance(points, np.ndarray):\n    #     points = points.numpy()\n    # if not isinstance(labels, np.ndarray):\n    #     labels = labels.numpy()\n    \n    df = pd.DataFrame({\n        \"x\": points[:, 0],\n        \"y\": points[:, 1],\n        \"z\": points[:, 2],\n        \"label\": labels\n    })\n    \n    fig = px.scatter_3d(\n        df, x=\"x\", y=\"y\", z=\"z\", color=\"label\",\n        labels={\"label\": \"Classes\"}, opacity=0.7\n    )\n    fig.update_traces(marker=dict(size=3, line=dict(width=1, color='DarkSlateGrey')), selector=dict(mode='markers'))\n    fig.update_layout(\n        title=\"Interactive Point Cloud Visualization\",\n        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n        legend_title=\"Labels\"\n    )\n    fig.show()\n\n# Example usage\nvisualize_point_cloud_interactive(dataset_train[100])\n# visualize_point_cloud_interactive(dataset_train[300])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:06:02.661250Z","iopub.execute_input":"2025-10-10T09:06:02.661670Z","iopub.status.idle":"2025-10-10T09:06:06.930080Z","shell.execute_reply.started":"2025-10-10T09:06:02.661644Z","shell.execute_reply":"2025-10-10T09:06:06.928683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\n\n####################################\n# DGCNN Segmentation Model\n####################################\ndef knn(x, k):\n    B, C, N = x.size()\n    inner = -2 * torch.matmul(x.transpose(2, 1), x)\n    xx = torch.sum(x ** 2, dim=1, keepdim=True)\n    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n    _, idx = pairwise_distance.topk(k=k, dim=-1)\n    return idx\n\ndef get_graph_feature(x, k=20, idx=None):\n    B, C, N = x.size()\n    if idx is None:\n        idx = knn(x, k=k)\n    idx_base = torch.arange(0, B, device=x.device).view(-1, 1, 1) * N\n    idx = idx + idx_base\n    idx = idx.view(-1)\n    x = x.transpose(2, 1).contiguous()\n    feature = x.view(B * N, -1)[idx, :]\n    feature = feature.view(B, N, k, C)\n    x = x.view(B, N, 1, C).repeat(1, 1, k, 1)\n    feature = torch.cat((feature - x, x), dim=3).permute(0, 3, 1, 2)\n    return feature\n\nclass DGCNN_Seg(nn.Module):\n    def __init__(self, num_classes=50, num_categories=16, k=20, emb_dims=1024, dropout=0.5):\n        super(DGCNN_Seg, self).__init__()\n        self.k = k\n        self.num_classes = num_classes\n\n        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n                                   nn.BatchNorm2d(64), nn.ReLU())\n        self.conv2 = nn.Sequential(nn.Conv2d(128, 64, kernel_size=1, bias=False),\n                                   nn.BatchNorm2d(64), nn.ReLU())\n        self.conv3 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=1, bias=False),\n                                   nn.BatchNorm2d(128), nn.ReLU())\n        self.conv4 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=1, bias=False),\n                                   nn.BatchNorm2d(256), nn.ReLU())\n        self.conv5 = nn.Sequential(nn.Conv1d(512, emb_dims, kernel_size=1, bias=False),\n                                   nn.BatchNorm1d(emb_dims), nn.ReLU())\n\n        # combine global + category features + local\n        self.conv6 = nn.Sequential(nn.Conv1d(emb_dims + num_categories, 256, kernel_size=1, bias=False),\n                                   nn.BatchNorm1d(256), nn.ReLU())\n        self.dp1 = nn.Dropout(p=dropout)\n        self.conv7 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=1, bias=False),\n                                   nn.BatchNorm1d(256), nn.ReLU())\n        self.dp2 = nn.Dropout(p=dropout)\n        self.conv8 = nn.Conv1d(256, num_classes, kernel_size=1, bias=True)\n\n    def forward(self, x, cat_onehot):\n        # x: (B, N, 3), cat_onehot: (B, num_categories)\n        x = x.permute(0, 2, 1)  # -> (B, 3, N)\n        # print(f\"x is{x.shape}\")\n        B, _, N = x.size()\n\n        x1 = self.conv1(get_graph_feature(x, k=self.k)).max(dim=-1)[0]\n        # print(f\"x1 is{x1.shape}\")\n        x2 = self.conv2(get_graph_feature(x1, k=self.k)).max(dim=-1)[0]\n        # print(f\"x2 is{x2.shape}\")\n        x3 = self.conv3(get_graph_feature(x2, k=self.k)).max(dim=-1)[0]\n        # print(f\"x3 is{x3.shape}\")\n        x4 = self.conv4(get_graph_feature(x3, k=self.k)).max(dim=-1)[0]\n        # print(f\"x4 is{x4.shape}\")\n        x_cat = torch.cat((x1, x2, x3, x4), dim=1).to(device)\n        # print(f\"x_cat is{x_cat.shape}\")\n        x_global = self.conv5(x_cat)  # (B, emb_dims, N)\n        # print(f\"x_global is:{x_global.shape}\")\n        # x_max = F.adaptive_max_pool1d(x_global, 1).view(B, -1)  # (B, emb_dims)\n        \n        # batch_categories shape: [B] or [B,1]\n        # num_categories = num_categories.squeeze()       # shape [B]\n        # batch_categories = torch.randint(0, 16, (B,))\n        # print(f\"cat_onehot is:{cat_onehot.shape}\")\n        # print(cat_onehot)\n        cat_onehot = F.one_hot(cat_onehot, num_classes=16).float()  # shape [B,16]\n        # print(cat_onehot)\n        # print(f\"cat_onehot is:{cat_onehot.shape}\")\n        # print(f\"cat_onehot is{cat_onehot.shape}\")\n        # expand to N points\n        # B, N = points.size(0), points.size(1)\n        cat_expand = cat_onehot.view(B, 16, 1).repeat(1, 1, N).to(x.device)  # shape [B,16,N]\n        # print(f\"cat_expand is:{cat_expand.shape}\")\n        # print(cat_expand)\n        \n        # cat_expand = cat_onehot.view(B, -1, 1).repeat(1, 1, N)  # (B, num_categories, N)\n        # print(f\"cat_expand is {cat_expand.shape}\")\n        \n        x = torch.cat((x_global, cat_expand), dim=1)  # (B, 1024+16=1040, N)\n        # print(f\"x is:{x.shape}\")\n        x = self.conv6(x)\n        x = self.dp1(x)\n        x = self.conv7(x)\n        x = self.dp2(x)\n        x = self.conv8(x)  # (B, num_classes, N)\n        x = F.log_softmax(x, dim=1)\n        return x\n\n####################################\n# Training Loop\n####################################\ndef train_dgcnn_seg(model, train_loader, val_loader, num_classes, num_categories, device, epochs=100):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n\n    best_val_acc = 0\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss, total_correct, total_seen = 0.0, 0, 0\n        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\") as t:\n            for points, cat_onehot, seg_labels in t:\n                # points: (B,N,3), cat_onehot: (B, num_categories), seg_labels: (B,N)\n                points = points.to(device)\n                cat_onehot = cat_onehot.to(device)\n                seg_labels = seg_labels.to(device).long()\n\n                optimizer.zero_grad()\n                preds = model(points, cat_onehot)  # (B,num_classes,N)\n                preds = preds.permute(0, 2, 1).contiguous()  # (B,N,num_classes)\n                loss = criterion(preds.view(-1, num_classes), seg_labels.view(-1))\n                loss.backward()\n                optimizer.step()\n\n                pred_choice = preds.argmax(dim=2)\n                correct = pred_choice.eq(seg_labels).sum().item()\n                total_correct += correct\n                total_seen += seg_labels.numel()\n                total_loss += loss.item()\n\n                t.set_postfix({\n                    \"loss\": f\"{total_loss / len(train_loader):.4f}\",\n                    \"acc\": f\"{total_correct / total_seen:.4f}\"\n                })\n        scheduler.step()\n\n        # validation\n        model.eval()\n        val_correct, val_seen = 0, 0\n        with torch.no_grad():\n            for points, cat_onehot, seg_labels in val_loader:\n                points = points.to(device)\n                cat_onehot = cat_onehot.to(device)\n                seg_labels = seg_labels.to(device).long()\n                preds = model(points, cat_onehot)\n                preds = preds.permute(0, 2, 1)\n                pred_choice = preds.argmax(dim=2)\n                val_correct += pred_choice.eq(seg_labels).sum().item()\n                val_seen += seg_labels.numel()\n        val_acc = val_correct / val_seen\n        print(f\"Val Acc: {val_acc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), \"best_dgcnn_seg.pth\")\n\n    print(f\"âœ… Training complete. Best Val Acc: {best_val_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:12:00.218233Z","iopub.execute_input":"2025-10-10T09:12:00.218512Z","iopub.status.idle":"2025-10-10T09:12:00.243678Z","shell.execute_reply.started":"2025-10-10T09:12:00.218493Z","shell.execute_reply":"2025-10-10T09:12:00.242682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_classes = 50\nnum_categories = 16\nmodel = DGCNN_Seg(num_classes=num_classes, num_categories=num_categories).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:12:31.009991Z","iopub.execute_input":"2025-10-10T09:12:31.010465Z","iopub.status.idle":"2025-10-10T09:12:31.054358Z","shell.execute_reply.started":"2025-10-10T09:12:31.010434Z","shell.execute_reply":"2025-10-10T09:12:31.053334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 8\ntrain_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nval_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n\ntrain_dgcnn_seg(model, train_loader, val_loader, num_classes, num_categories, device, epochs=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:06:17.208140Z","iopub.execute_input":"2025-10-10T09:06:17.208474Z","iopub.status.idle":"2025-10-10T09:06:56.880381Z","shell.execute_reply.started":"2025-10-10T09:06:17.208449Z","shell.execute_reply":"2025-10-10T09:06:56.879060Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import your DGCNN model class\nfrom model import DGCNN_Seg  # or wherever your class is defined\n\nnum_classes = 50  # replace with your dataset's number of segmentation classes\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = DGCNN(num_classes=num_classes).to(device)\ncheckpoint_path = \"/kaggle/working/best_dgcnn_seg.pth\"  # path to your .pth file\nmodel.load_state_dict(torch.load(checkpoint_path, map_location=device))\n# model.eval()  # important for inference\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:12:33.731618Z","iopub.execute_input":"2025-10-10T09:12:33.731986Z","iopub.status.idle":"2025-10-10T09:12:33.745445Z","shell.execute_reply.started":"2025-10-10T09:12:33.731960Z","shell.execute_reply":"2025-10-10T09:12:33.744152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = DGCNN_Seg(num_classes=num_classes).to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_dgcnn_seg.pth\", map_location=device))\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:14:16.911428Z","iopub.execute_input":"2025-10-10T09:14:16.911737Z","iopub.status.idle":"2025-10-10T09:14:16.939291Z","shell.execute_reply.started":"2025-10-10T09:14:16.911717Z","shell.execute_reply":"2025-10-10T09:14:16.938223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport time\nimport numpy as np\nimport psutil\nimport os\n\nBATCH_SIZE = 16\ntest_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n\ndef compute_metrics_dgcnn(model, dataloader, num_classes, device):\n    \"\"\"\n    Evaluate DGCNN segmentation model on a dataloader.\n    Returns: dict with loss, accuracy, IoU, inference time, memory, model size\n    \"\"\"\n    model.eval()\n    total_correct, total_seen = 0, 0\n    total_loss = 0.0\n    all_iou_per_instance = []\n    part_intersection = np.zeros(num_classes)\n    part_union = np.zeros(num_classes)\n    criterion = torch.nn.NLLLoss()  # log_softmax outputs\n\n    start_time = time.time()\n    with torch.no_grad():\n        for points, category, seg in dataloader:\n            points = points.to(device, dtype=torch.float32)         # (B, N, 3)\n            category = category.to(device, dtype=torch.long).squeeze()  # (B,)\n            seg = seg.to(device, dtype=torch.long)                 # (B, N)\n\n            # -------- Forward pass --------\n            preds= model(points, category)  # (B, N, num_classes)\n            preds = preds.transpose(1, 2).contiguous()\n\n            # Flatten for loss computation\n            preds_flat = preds.view(-1, num_classes)  # (B*N, num_classes)\n            seg_flat = seg.view(-1)                   # (B*N,)\n\n            # Compute loss (no feature transform in DGCNN)\n            loss = criterion(preds_flat, seg_flat)\n            total_loss += loss.item()\n\n            # -------- Predictions --------\n            pred_choice = preds_flat.argmax(dim=1)  # (B*N,)\n            total_correct += pred_choice.eq(seg_flat).sum().item()\n            total_seen += seg_flat.numel()\n\n            # -------- IoU per instance --------\n            preds_np = pred_choice.cpu().numpy().reshape(points.size(0), -1)\n            seg_np = seg.cpu().numpy().reshape(points.size(0), -1)\n            for shape_idx in range(points.size(0)):\n                part_iou = []\n                for part in np.unique(seg_np[shape_idx]):\n                    I = np.sum((preds_np[shape_idx] == part) & (seg_np[shape_idx] == part))\n                    U = np.sum((preds_np[shape_idx] == part) | (seg_np[shape_idx] == part))\n                    iou = 1.0 if U == 0 else I / float(U)\n                    part_iou.append(iou)\n                    part_intersection[part] += I\n                    part_union[part] += U\n                all_iou_per_instance.append(np.mean(part_iou))\n\n    # -------- Metrics --------\n    total_time = time.time() - start_time\n    num_samples = len(dataloader.dataset)\n    avg_inference_time = total_time / num_samples\n\n    overall_acc = total_correct / total_seen\n\n    instance_miou = np.mean(all_iou_per_instance)\n    class_miou = np.mean(part_intersection / np.maximum(part_union, 1e-6))\n\n    # -------- Memory usage --------\n    process = psutil.Process(os.getpid())\n    memory_mb = process.memory_info().rss / 1024 ** 2  # in MB\n\n    # -------- Model size --------\n    param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n    buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n    model_size_mb = (param_size + buffer_size) / 1024 ** 2\n\n    return {\n        'loss': total_loss / len(dataloader),\n        'overall_acc': overall_acc,\n        'instance_miou': instance_miou,\n        'class_miou': class_miou,\n        'avg_inference_time': avg_inference_time,\n        'memory_mb': memory_mb,\n        'model_size_mb': model_size_mb\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T08:41:12.256879Z","iopub.execute_input":"2025-10-10T08:41:12.257155Z","iopub.status.idle":"2025-10-10T08:41:12.268803Z","shell.execute_reply.started":"2025-10-10T08:41:12.257135Z","shell.execute_reply":"2025-10-10T08:41:12.268008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_CLASSES=50\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmetrics = compute_metrics_dgcnn(model, val_loader, NUM_CLASSES, DEVICE)\n\nprint(f\"\\nValidation Metrics:\")\nprint(f\"Loss:              {metrics['loss']:.4f}\")\nprint(f\"Overall Accuracy:  {metrics['overall_acc']:.4f}\")\nprint(f\"Instance mIoU:     {metrics['instance_miou']:.4f}\")\nprint(f\"Class mIoU:        {metrics['class_miou']:.4f}\")\nprint(f\"Inference Time:    {metrics['avg_inference_time']*1000:.2f} ms per sample\")\nprint(f\"Memory Usage:      {metrics['memory_mb']:.2f} MB\")\nprint(f\"Model Size:        {metrics['model_size_mb']:.2f} MB\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T08:41:15.665374Z","iopub.execute_input":"2025-10-10T08:41:15.665948Z","iopub.status.idle":"2025-10-10T08:42:00.725587Z","shell.execute_reply.started":"2025-10-10T08:41:15.665927Z","shell.execute_reply":"2025-10-10T08:42:00.724759Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## comparison brooo","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndef plot_single_segmentation_with_category(points, seg_gt, seg_pred, category_name=\"Unknown\", shape_idx=0):\n    \"\"\"\n    points: (N, 3) numpy array of point cloud coordinates\n    seg_gt: (N,) numpy array of ground truth labels\n    seg_pred: (N,) numpy array of predicted labels\n    category_name: string label for the object category\n    shape_idx: integer index of the object\n    \"\"\"\n\n    fig = make_subplots(\n        rows=1, cols=2,\n        specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n        subplot_titles=[\n            f\"Ground Truth - {category_name} (Object {shape_idx})\",\n            f\"Prediction - {category_name} (Object {shape_idx})\"\n        ]\n    )\n\n    # Ground truth segmentation\n    fig.add_trace(go.Scatter3d(\n        x=points[:, 0],\n        y=points[:, 1],\n        z=points[:, 2],\n        mode='markers',\n        marker=dict(\n            size=2,\n            color=seg_gt,\n            colorscale='Viridis',\n            opacity=0.8,\n            colorbar=dict(title=\"GT Labels\")\n        ),\n        name=\"Ground Truth\"\n    ), row=1, col=1)\n\n    # Predicted segmentation\n    fig.add_trace(go.Scatter3d(\n        x=points[:, 0],\n        y=points[:, 1],\n        z=points[:, 2],\n        mode='markers',\n        marker=dict(\n            size=2,\n            color=seg_pred,\n            colorscale='Rainbow',\n            opacity=0.8,\n            colorbar=dict(title=\"Predicted Labels\")\n        ),\n        name=\"Prediction\"\n    ), row=1, col=2)\n\n    fig.update_layout(\n        title=f\"Segmentation Comparison for Category: {category_name}\",\n        width=1200,\n        height=600\n    )\n\n    fig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T08:36:55.071563Z","iopub.execute_input":"2025-10-10T08:36:55.072350Z","iopub.status.idle":"2025-10-10T08:36:55.187438Z","shell.execute_reply.started":"2025-10-10T08:36:55.072325Z","shell.execute_reply":"2025-10-10T08:36:55.186731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ndevice = DEVICE\nnum_classes = NUM_CLASSES\n\n# Keep track of which categories we've already visualized\nshown_categories = set()\n\nwith torch.no_grad():\n    for points, category, seg in test_loader:\n        points = points.to(device, dtype=torch.float32)              # (B, N, 3)\n        category = category.to(device, dtype=torch.long).squeeze()   # (B,)\n        seg = seg.to(device, dtype=torch.long)                       # (B, N)\n\n        # -------- Forward pass --------\n        preds = model(points, category)  # (B, N, num_classes)\n\n        # Flatten predictions for argmax\n        preds_flat = preds.view(-1, num_classes)  # (B*N, num_classes)\n        seg_flat = seg.view(-1)                   # (B*N,)\n        pred_choice = preds_flat.argmax(dim=1)    # (B*N,)\n\n        # Reshape back to per-point per-sample\n        preds_np = pred_choice.cpu().numpy().reshape(points.size(0), -1)  # (B, N)\n        seg_np = seg.cpu().numpy().reshape(points.size(0), -1)             # (B, N)\n\n        # -------- Iterate over batch items --------\n        for b in range(points.size(0)):\n            cat_id = category[b].item()\n            cat_name = index_to_category[cat_id]\n\n            # Skip if already visualized this category\n            if cat_name in shown_categories:\n                continue\n\n            # Plot one sample of this category\n            plot_single_segmentation_with_category(\n                points[b].cpu().numpy(),  # (N, 3)\n                seg_np[b],                # ground truth labels\n                preds_np[b],              # predicted labels\n                category_name=cat_name,\n                shape_idx=b\n            )\n\n            shown_categories.add(cat_name)\n            print(f\"âœ… Shown category: {cat_name} ({len(shown_categories)}/16)\")\n\n            # Stop once all 16 categories have been shown\n            if len(shown_categories) == 16:\n                print(\"\\nðŸŽ‰ Displayed one sample from each of the 16 categories. Done!\")\n                break\n\n        # Stop outer loop if done\n        if len(shown_categories) == 16:\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T08:36:57.972884Z","iopub.execute_input":"2025-10-10T08:36:57.973115Z","iopub.status.idle":"2025-10-10T08:37:11.616096Z","shell.execute_reply.started":"2025-10-10T08:36:57.973099Z","shell.execute_reply":"2025-10-10T08:37:11.615371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}